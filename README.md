## Commit 1 Reflection notes
In this commit, I dove into building a simple, single-threaded web server in Rust. I set up a TcpListener on 127.0.0.1:7878 to accept connections from my browser, and used a BufReader to process each HTTP request line by line until I reached the end of the header section. This hands-on experience not only gave me a clearer picture of how HTTP requests work but also highlighted Rust’s powerful network programming capabilities. Even though I used unwrap() for simplicity, it was a great reminder of the importance of proper error handling, which I plan to refine later. Overall, this project has been both challenging and rewarding, and I'm excited to explore further improvements like better response handling and concurrency in the future.

## Commit 2 Reflection notes
![Commit 2 screen capture](/assets/images/commit2.png)

In this commit, I took a significant step forward by updating my Rust web server to serve a proper HTML page. I learned that returning a web page involves more than just sending raw data; it requires crafting a well-formed HTTP response that includes essential headers like "Content-Length" so that the browser knows how much data to expect. Reading the HTML file from disk, calculating its length, and formatting the response correctly with CRLF line breaks deepened my understanding of HTTP protocols and the inner workings of a web server. This hands-on experience has not only boosted my confidence in handling file I/O and string manipulation in Rust, but also highlighted the importance of following protocol standards to ensure seamless communication between the server and the browser.

## Commit 3 Reflection notes
![Commit 3 screen capture](/assets/images/commit3.png)

In this commit, I refactored my Rust web server to validate incoming HTTP requests and selectively respond based on the requested URL. Instead of serving the same content regardless of the URL, I now inspect the first line of the request. If it matches "GET / HTTP/1.1", the server responds with a 200 OK status and serves the hello.html file. For any other request, it returns a 404 NOT FOUND status along with a custom 404.html page. This approach not only simulates basic routing—similar to what production servers perform—but also improves code organization by separating the logic for handling valid and invalid requests. Through this process, I deepened my understanding of HTTP status codes, proper header formatting, and the importance of maintainable code in server design.

## Commit 4 Reflection notes

In this commit, I decided to add a /sleep route to my Rust server to simulate a slow request, where the server deliberately pauses for 10 seconds before sending its response. When I opened two browser windows, one hitting 127.0.0.1/sleep and the other accessing 127.0.0.1, I immediately noticed that the normal request took much longer to load than it should have. This experiment made me realize that my single-threaded server processes one connection at a time; while it’s busy waiting during the sleep period, every other request has to stand in line until the slow operation completes. I couldn’t help but imagine the frustration of having many users waiting for their pages to load under such conditions, which really drove home the limitations of this design. It became clear to me that to build a responsive and scalable system, I need to explore multi-threading or asynchronous I/O techniques so that one slow request won’t block the entire server. This hands-on test not only deepened my understanding of server architecture but also reinforced the importance of designing with concurrency in mind.

## Commit 5 Reflection notes

In this commit, I Integrated the ThreadPool into my server was a game changer. By refactoring my code to route incoming connections through a pool of four worker threads instead of handling them sequentially, I managed to improve the server’s responsiveness significantly—especially noticeable when processing the simulated slow /sleep route. I replaced the direct call to handle_connection with a call to pool.execute, which allowed multiple requests to be handled concurrently. This hands-on experiment deepened my understanding of Rust’s concurrency primitives, such as channels, Arc, and Mutex, and showed me firsthand how critical non-blocking design is for scalable server applications. Overall, this experience not only resolved the performance bottleneck I had with a single-threaded model but also motivated me to explore further advancements like asynchronous I/O for even more efficient processing in future projects.